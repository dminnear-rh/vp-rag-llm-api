# === RAG DB ===
QDRANT_URL=http://127.0.0.1:6333
QDRANT_COLLECTION=rag-collection

# === Default Model Name ===
DEFAULT_MODEL=mistral

# === Model Registry (JSON array)
# model_type: one of "vllm" | "openai" | etc.
# max_tokens is the total usable for prompt + response.
VLLM_MODELS=[{"name": "mistral", "url": "http://127.0.0.1:8000", "model_type": "vllm", "max_total_tokens": 32768}, {"name": "gpt-4o", "url": "https://api.openai.com/v1/chat/completions", "model_type": "openai", "max_total_tokens": 128000}, {"name": "gpt-4o-mini", "url": "https://api.openai.com/v1/chat/completions", "model_type": "openai", "max_total_tokens": 128000}]

# === Logging ===
LOG_LEVEL=info

# === API Keys ===
OPENAI_API_KEY=replaceme

# === RAG DB Embedding Model ===
EMBEDDING_MODEL=BAAI/bge-large-en-v1.5

# === Cross Encoder Model ===
CROSS_ENCODER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# === Prompt Config ===
SYSTEM_MESSAGE="You are an expert in Red Hat OpenShift and Kubernetes application architecture, specializing in the design, implementation, and validation of OpenShift Validated Patterns. The user is seeking to better understand Validated Patterns including how they are built, tested, used across industries, or extended for new use cases. Use the following documentation and source content to generate a clear and practical answer. Your response should: - Reference relevant concepts or implementation details from the provided context - Be technically accurate and aimed at architects, engineers, or contributors - Include examples or explanations using OpenShift-native tools and practices (e.g., GitOps, Operators, Pipelines, Secrets management)"
MAX_RESPONSE_TOKENS=4096
